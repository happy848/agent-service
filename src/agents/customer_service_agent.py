# æµ‹è¯•å®¢æœæœºå™¨äººå·¥ä½œæµæ–‡æ¡£ docs/customer_service_agent.md
# æœºå™¨äººå·¥ä½œæµï¼š
# 1. ç”¨æˆ·èƒŒæ™¯ä¿¡æ¯æŸ¥è¯¢å’Œé—®é¢˜åˆ†ç±»å¹¶è¡Œæ‰§è¡Œ
# 2. æ¨ç†å›ç­”ã€è‡ªæˆ‘æ£€æŸ¥ã€æ‹Ÿäººå›å¤ä¸²è¡Œæ‰§è¡Œ
# 3. é—®é¢˜åˆ†ç±»ç»†åŒ–
# 4. æ‹ŸäººåŒ–è¯­è¨€é£æ ¼

from datetime import datetime
from typing import Literal, List, Dict, Any, Optional, Annotated
import re
import operator

from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage
from langchain_core.runnables import RunnableConfig, RunnableLambda, RunnableSerializable
from langchain_core.tools import tool
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, MessagesState, StateGraph, START
from langgraph.prebuilt import create_react_agent

from core import get_model, settings
from schema import ChatMessage
from tools.user_info import get_user_info, get_user_orders, get_user_parcels, UserData

import logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


# Define tools for customer service agent
@tool
def get_order_status(order_id: str) -> Dict[str, Any]:
    """Get the status of an order."""
    # Mock order status - replace with actual database query
    return {
        "status": "processing",
        "estimated_delivery": "2024-03-20",
        "tracking_number": "ABC123XYZ"
    }

@tool
def calculate_shipping_cost(weight_kg: float, destination: str) -> Dict[str, Any]:
    """Calculate shipping cost based on weight and destination."""
    # Mock shipping calculation - replace with actual logic
    base_rate = 25.0  # Base rate for first kg
    additional_rate = 12.0  # Rate per additional kg
    
    total_cost = base_rate + (weight_kg - 1) * additional_rate if weight_kg > 1 else base_rate
    
    return {
        "base_rate": base_rate,
        "total_cost": round(total_cost, 2),
        "currency": "USD",
        "estimated_days": "8-11"
    }

@tool
async def categorize_message(message: str) -> Dict[str, Any]:
    """Categorize the customer message to determine intent."""
    # æ ¹æ®æ–‡æ¡£è¦æ±‚çš„5ä¸ªå…·ä½“åˆ†ç±»
    categories = {
        "new_user_onboarding": ["æ³¨å†Œ", "ç™»å½•", "æ€ä¹ˆä½¿ç”¨", "å¦‚ä½•ä½¿ç”¨", "æ–°ç”¨æˆ·", "ç¬¬ä¸€æ¬¡", "æ•™ç¨‹", "guide", "register", "login", "how to use", "first time", "tutorial"],
        "payment_issues": ["æ”¯ä»˜", "ä»˜æ¬¾", "å……å€¼", "ä½™é¢", "æ‰‹ç»­è´¹", "è½¬è´¦", "revolut", "wise", "payment", "pay", "top up", "balance", "fee", "transfer"],
        "order_issues": ["è®¢å•", "å¤šä¹…åˆ°ä»“åº“", "å¤šä¹…åˆ°å®¶", "è´¨æ£€ç…§ç‰‡", "é€€è´§", "order", "warehouse", "delivery time", "quality check", "return", "refund"],
        "parcel_issues": ["åŒ…è£¹", "è¿è´¹", "åŒ…è£¹çŠ¶æ€", "è¢«æ²¡æ”¶", "tracking", "parcel", "shipping cost", "parcel status", "confiscated"],
        "other_issues": ["å¹³å°ä»‹ç»", "å¹³å°æ”¿ç­–", "å¹³å°æ´»åŠ¨", "å…¶ä»–", "ä»‹ç»", "æ”¿ç­–", "æ´»åŠ¨", "platform", "policy", "activity", "other"]
    }
    
    message_lower = message.lower()
    detected_categories = []
    
    # é¦–å…ˆå°è¯•å…³é”®è¯åŒ¹é…
    for category, keywords in categories.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_categories.append(category)
    
    # å¦‚æœå…³é”®è¯åŒ¹é…æˆåŠŸï¼Œç›´æ¥è¿”å›ç»“æœ
    if detected_categories:
        return {
            "categories": detected_categories,
            "confidence": 0.9,
            "method": "keyword_matching"
        }
    
    # å¦‚æœæ²¡æœ‰å…³é”®è¯å‘½ä¸­ï¼Œä½¿ç”¨å¤§æ¨¡å‹æ¨ç†
    try:
        model = get_model(settings.DEFAULT_MODEL)
        
        classification_prompt = f"""è¯·åˆ†æä»¥ä¸‹å®¢æˆ·æ¶ˆæ¯ï¼Œå°†å…¶åˆ†ç±»åˆ°æœ€åˆé€‚çš„ç±»åˆ«ä¸­ã€‚
            å®¢æˆ·æ¶ˆæ¯ï¼š{message}
            å¯é€‰åˆ†ç±»ï¼š
            1. new_user_onboarding - æ–°ç”¨æˆ·å¼•å¯¼ï¼ˆæ³¨å†Œã€ç™»å½•ã€å¦‚ä½•ä½¿ç”¨å¹³å°ã€æ•™ç¨‹ç­‰ï¼‰
            2. payment_issues - æ”¯ä»˜é—®é¢˜ï¼ˆæ”¯ä»˜ã€å……å€¼ã€ä½™é¢ã€æ‰‹ç»­è´¹ã€è½¬è´¦ç­‰ï¼‰
            3. order_issues - è®¢å•é—®é¢˜ï¼ˆè®¢å•çŠ¶æ€ã€åˆ°è´§æ—¶é—´ã€è´¨æ£€ã€é€€è´§ç­‰ï¼‰
            4. parcel_issues - åŒ…è£¹é—®é¢˜ï¼ˆåŒ…è£¹çŠ¶æ€ã€è¿è´¹ã€ç‰©æµã€è¢«æ²¡æ”¶ç­‰ï¼‰
            5. other_issues - å…¶ä»–é—®é¢˜ï¼ˆå¹³å°ä»‹ç»ã€æ”¿ç­–ã€æ´»åŠ¨ç­‰ï¼‰
            è¯·åªè¿”å›åˆ†ç±»åç§°ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚å¦‚æœæ¶ˆæ¯æ¶‰åŠå¤šä¸ªç±»åˆ«ï¼Œè¯·é€‰æ‹©æœ€ä¸»è¦çš„ä¸€ä¸ªã€‚
            åˆ†ç±»ç»“æœï¼š"""

        messages = [
            SystemMessage(content=classification_prompt),
            HumanMessage(content="è¯·è¿›è¡Œåˆ†ç±»")
        ]
        
        response = await model.ainvoke(messages)
        llm_category = response.content.strip().lower()
        
        # éªŒè¯LLMè¿”å›çš„åˆ†ç±»æ˜¯å¦æœ‰æ•ˆ
        valid_categories = list(categories.keys())
        if llm_category in valid_categories:
            detected_categories = [llm_category]
            confidence = 0.7  # LLMæ¨ç†çš„ç½®ä¿¡åº¦ç¨ä½
        else:
            # å¦‚æœLLMè¿”å›çš„åˆ†ç±»æ— æ•ˆï¼Œé»˜è®¤ä¸ºother_issues
            detected_categories = ["other_issues"]
            confidence = 0.5
            
        return {
            "categories": detected_categories,
            "confidence": confidence,
            "method": "llm_inference",
            "llm_raw_response": llm_category
        }
        
    except Exception as e:
        logger.warning(f"LLM inference failed for message categorization: {e}")
        # å¦‚æœLLMæ¨ç†å¤±è´¥ï¼Œé»˜è®¤ä¸ºother_issues
        return {
            "categories": ["other_issues"],
            "confidence": 0.3,
            "method": "fallback"
        }

class CustomerServiceState(MessagesState, total=False):
    """State for customer service agent."""
    # ä½¿ç”¨operator.addä½œä¸ºreducerï¼Œæ”¯æŒå¹¶è¡Œæ‰§è¡Œæ—¶çš„çŠ¶æ€åˆå¹¶
    categories: Annotated[Dict[str, Any], operator.add]
    user_info: Optional[UserData]
    user_token: Optional[str]
    background_info: Annotated[Dict[str, Any], operator.add]  # ç”¨æˆ·èƒŒæ™¯ä¿¡æ¯
    reasoning_response: Optional[str]  # æ¨ç†å›ç­”
    humanized_response: Optional[str]  # æ‹Ÿäººå›å¤
    self_check_passed: Optional[bool]  # è‡ªæˆ‘æ£€æŸ¥ç»“æœ

def wrap_model(model: BaseChatModel) -> RunnableSerializable[CustomerServiceState, AIMessage]:
    """Wrap the model with system prompt and state handling."""
    
    def create_system_prompt(state: CustomerServiceState) -> str:
        base_prompt = """You are a professional customer service agent for an international purchasing agency.
        Your role is to assist customers with their orders, shipping inquiries, and general questions.
        Always be polite, professional, and helpful. Match the language of the customer in your responses.
        
        Key business points:
        1. We help customers purchase products internationally
        2. Shipping typically takes 8-11 working days
        3. Base shipping rate is $25 for first kg, $12 for each additional kg
        4. We accept payments via bank transfer (SEPA/SWIFT) or Revolut/Wise
        5. All prices are in USD unless specified otherwise
        
        Ordering Process:
        1. Customer pastes product link into our search bar
        2. They select product options and add to cart
        3. Submit order and top up balance
        4. We purchase and ship to warehouse
        5. Customer creates shipping parcel
        6. Pay shipping fee and we deliver internationally
        
        WhatsApp Message Guidelines:
        - Keep each message under 300 characters when possible
        - For long explanations, split into multiple shorter messages
        - Use line breaks to improve readability
        - Start new messages for new topics or steps
        - Use emojis sparingly but effectively
        - End each message with a clear call to action
        
        Remember to:
        - Be concise and direct - WhatsApp users prefer shorter messages
        - Use bullet points for lists
        - Break down complex information into digestible chunks
        - Show empathy when dealing with issues
        - Maintain a professional but friendly tone
        - Reference previous messages when relevant
        - Acknowledge time gaps appropriately
        - Add friendly emojis to seem more human-like
        - Use casual, conversational language while maintaining professionalism
        - NEVER include timestamps in your responses
        - ALWAYS use "\n\n" to indicate where a message should be split into separate WhatsApp messages"""
        
        # æ·»åŠ ç”¨æˆ·ä¿¡æ¯åˆ°ç³»ç»Ÿæç¤º
        user_info = state.get("user_info")
        if user_info:
            user_context = f"""
        
        Current Customer Information:
        - Email: {user_info.email}
        - VIP Level: {user_info.vip_level}
        - Balance: {user_info.balance_cny} CNY
        - Service Rate: {user_info.service_rate}%
        - Currency: {user_info.currency_unit}
        - Account Status: {'Verified' if user_info.email_verification else 'Unverified'}
        
        Use this information to provide personalized service:
        - Address the customer by their VIP level when appropriate
        - Reference their current balance when discussing payments
        - Consider their service rate for pricing discussions
        - Adjust your tone based on their account verification status"""
            return base_prompt + user_context
        else:
            return base_prompt + "\n\nNote: Customer information not available. Provide general assistance."
    
    preprocessor = RunnableLambda(
        lambda state: [SystemMessage(content=create_system_prompt(state))] + state["messages"],
        name="StateModifier",
    )
    return preprocessor | model

async def categorize_customer_message(state: CustomerServiceState, config: RunnableConfig) -> CustomerServiceState:
    """Categorize the customer message to determine intent."""
    last_message = state["messages"][-1]
    if not isinstance(last_message, HumanMessage):
        return {"categories": {}}
        
    categories = await categorize_message(last_message.content)
    return {"categories": categories}

async def get_user_information(state: CustomerServiceState, config: RunnableConfig) -> CustomerServiceState:
    """Get user information using user_token from config."""
    try:
        # ä»configä¸­è·å–user_token
        user_token = config.get("configurable", {}).get("user_token")
        if not user_token:
            return {
                "user_info": None, 
                "user_token": None, 
                "background_info": {
                    "user_info": None,
                    "orders": [],
                    "parcels": []
                }
            }
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = await get_user_info(user_token)
        logger.info(f"User token: {user_token}")
        logger.info(f"User info: {user_info}")
        
        # å¹¶å‘è·å–ç”¨æˆ·è®¢å•å’ŒåŒ…è£¹ä¿¡æ¯
        background_info = {
            "user_info": user_info,
            "orders": [],
            "parcels": []
        }
        
        try:
            orders = await get_user_orders(user_token)
            background_info["orders"] = [order.dict() for order in orders]
        except Exception as e:
            logger.warning(f"Failed to get user orders: {e}")
            
        try:
            parcels = await get_user_parcels(user_token)
            background_info["parcels"] = [parcel.dict() for parcel in parcels]
        except Exception as e:
            logger.warning(f"Failed to get user parcels: {e}")
        
        return {
            "user_info": user_info, 
            "user_token": user_token,
            "background_info": background_info
        }
        
    except Exception as e:
        # å¦‚æœè·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
        logger.error(f"Failed to get user info: {e}")
        return {
            "user_info": None, 
            "user_token": user_token, 
            "background_info": {
                "user_info": None,
                "orders": [],
                "parcels": []
            }
        }

async def reasoning_response(state: CustomerServiceState, config: RunnableConfig) -> CustomerServiceState:
    """æ¨ç†å›ç­”ï¼šåŸºäºèƒŒæ™¯ä¿¡æ¯å’Œé—®é¢˜åˆ†ç±»è¿›è¡Œæ·±åº¦æ¨ç†"""
    m = get_model(config["configurable"].get("model", settings.DEFAULT_MODEL))
    
    # æ„å»ºæ¨ç†æç¤º
    user_message = state["messages"][-1].content if state["messages"] else ""
    categories = state.get("categories", {}).get("categories", [])
    background_info = state.get("background_info", {})
    
    reasoning_prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œç”Ÿæˆä¸“ä¸šã€å‡†ç¡®çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{user_message}
é—®é¢˜åˆ†ç±»ï¼š{categories}
ç”¨æˆ·èƒŒæ™¯ä¿¡æ¯ï¼š{background_info}

è¯·æ ¹æ®é—®é¢˜åˆ†ç±»æä¾›ç›¸åº”çš„ä¸“ä¸šå›ç­”ï¼š

1. æ–°ç”¨æˆ·onboardingï¼šè¯¦ç»†è¯´æ˜æ³¨å†Œæµç¨‹ã€å¹³å°ä½¿ç”¨æ–¹æ³•ã€è´­ç‰©è½¦åˆ¶ä½œã€æ”¯ä»˜æµç¨‹
2. æ”¯ä»˜é—®é¢˜ï¼šè§£é‡Šæ”¯ä»˜æ¸ é“ã€æ‰‹ç»­è´¹ã€å……å€¼æµç¨‹
3. è®¢å•é—®é¢˜ï¼šè¯´æ˜è®¢å•å¤„ç†æ—¶é—´ã€è´¨æ£€æµç¨‹ã€é€€è´§æ”¿ç­–
4. åŒ…è£¹é—®é¢˜ï¼šè§£é‡Šè¿è´¹æ„æˆã€é…é€æ—¶é—´ã€åŒ…è£¹çŠ¶æ€æŸ¥è¯¢ã€å¼‚å¸¸å¤„ç†
5. å…¶ä»–é—®é¢˜ï¼šæä¾›å¹³å°ä»‹ç»ã€æ”¿ç­–è¯´æ˜ã€æ´»åŠ¨ä¿¡æ¯

è¦æ±‚ï¼š
- å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šã€å®Œæ•´
- åŸºäºç”¨æˆ·èƒŒæ™¯ä¿¡æ¯æä¾›ä¸ªæ€§åŒ–å»ºè®®
- æä¾›å…·ä½“çš„æ“ä½œæ­¥éª¤å’Œè§£å†³æ–¹æ¡ˆ
"""
    
    messages = [
        SystemMessage(content=reasoning_prompt),
        HumanMessage(content=user_message)
    ]
    
    response = await m.ainvoke(messages, config)
    return {"reasoning_response": response.content}

async def self_check_response(state: CustomerServiceState, config: RunnableConfig) -> CustomerServiceState:
    """å›ç­”è‡ªæˆ‘æ£€æŸ¥ï¼šæ£€æŸ¥å›ç­”æ˜¯å¦å‡†ç¡®ã€å®Œæ•´ã€æ— å¹»è§‰"""
    m = get_model(config["configurable"].get("model", settings.DEFAULT_MODEL))
    
    reasoning_response = state.get("reasoning_response", "")
    user_message = state["messages"][-1].content if state["messages"] else ""
    
    check_prompt = f"""è¯·å¯¹ä»¥ä¸‹å®¢æœå›ç­”è¿›è¡Œè‡ªæˆ‘æ£€æŸ¥ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{user_message}
å®¢æœå›ç­”ï¼š{reasoning_response}

æ£€æŸ¥æ ‡å‡†ï¼š
1. æ˜¯å¦å‡†ç¡®å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜
2. æ˜¯å¦æœ‰äº‹å®é”™è¯¯æˆ–å¹»è§‰
3. æ˜¯å¦è¿èƒŒå¸¸è¯†
4. æ˜¯å¦å®Œæ•´æä¾›äº†è§£å†³æ–¹æ¡ˆ
5. æ˜¯å¦åŸºäºç”¨æˆ·èƒŒæ™¯ä¿¡æ¯æä¾›äº†ä¸ªæ€§åŒ–å»ºè®®

è¯·ç»™å‡ºæ£€æŸ¥ç»“æœï¼š
- å¦‚æœæ£€æŸ¥é€šè¿‡ï¼Œå›å¤"PASS"
- å¦‚æœæ£€æŸ¥ä¸é€šè¿‡ï¼Œå›å¤"FAIL"å¹¶è¯´æ˜åŸå› 

æ£€æŸ¥ç»“æœï¼š"""
    
    messages = [
        SystemMessage(content=check_prompt),
        HumanMessage(content="è¯·è¿›è¡Œè‡ªæˆ‘æ£€æŸ¥")
    ]
    
    response = await m.ainvoke(messages, config)
    check_result = response.content.strip()
    
    if "PASS" in check_result.upper():
        return {"self_check_passed": True}
    else:
        # æ£€æŸ¥ä¸é€šè¿‡ï¼Œéœ€è¦é‡æ–°æ¨ç†
        logger.warning(f"Self check failed: {check_result}")
        return {"self_check_passed": False, "check_feedback": check_result}

async def humanize_response(state: CustomerServiceState, config: RunnableConfig) -> CustomerServiceState:
    """æ‹Ÿäººå›å¤ï¼šå°†ä¸“ä¸šå›ç­”è½¬æ¢ä¸ºè‡ªç„¶ã€å£è¯­åŒ–çš„è¯­è¨€"""
    m = get_model(config["configurable"].get("model", settings.DEFAULT_MODEL))
    
    reasoning_response = state.get("reasoning_response", "")
    user_message = state["messages"][-1].content if state["messages"] else ""
    background_info = state.get("background_info", {})
    
    humanize_prompt = f"""è¯·å°†ä»¥ä¸‹ä¸“ä¸šå›ç­”è½¬æ¢ä¸ºè‡ªç„¶ã€å£è¯­åŒ–çš„æ‹Ÿäººå›å¤ï¼š

åŸå§‹å›ç­”ï¼š{reasoning_response}
ç”¨æˆ·é—®é¢˜ï¼š{user_message}

æ‹ŸäººåŒ–è¦æ±‚ï¼š
1. ä½¿ç”¨è‡ªç„¶ã€å£è¯­åŒ–çš„è¯­è¨€ï¼Œé¿å…ç”Ÿç¡¬ã€æœºæ¢°çš„è¡¨è¿°
2. é¿å…è¿‡äºä¸“ä¸šçš„æœ¯è¯­ï¼Œä½¿ç”¨æ—¥å¸¸äº¤æµä¹ æƒ¯çš„è¡¨è¾¾
3. æ ¹æ®é—®é¢˜æ€§è´¨èå…¥ç§¯æçš„æƒ…æ„Ÿå…ƒç´ ï¼š
   - è§£å†³é—®é¢˜åè¡¨è¾¾"å¾ˆé«˜å…´èƒ½ä¸ºæ‚¨è§£å†³è¿™ä¸ªé—®é¢˜"
   - ç”¨æˆ·é‡åˆ°å›°æ‰°æ—¶è¡¨è¾¾"éå¸¸ç†è§£æ‚¨çš„å¿ƒæƒ…"
4. é€‚å½“æ·»åŠ è¯­æ°”è¯ï¼ˆå¦‚"å‘¢""å•¦""å“¦"ï¼‰å’Œè¡¨æƒ…ç¬¦å·ï¼ˆğŸ˜Šã€ğŸ‘ç­‰ï¼‰
5. ä½¿ç”¨ç¬¬ä¸€äººç§°ï¼ˆæˆ‘ã€æˆ‘ä»¬ï¼‰å’Œç¬¬äºŒäººç§°ï¼ˆæ‚¨ï¼‰å¢å¼ºäº’åŠ¨æ„Ÿ
6. æ ¹æ®ç”¨æˆ·èƒŒæ™¯ä¿¡æ¯è¿›è¡Œä¸ªæ€§åŒ–è°ƒæ•´
7. åœ¨ç»“å°¾æ·»åŠ å‹å¥½çš„äº’åŠ¨è¯­å¥ï¼Œå¦‚"å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–ç–‘é—®ï¼Œæ¬¢è¿éšæ—¶å‘æˆ‘å’¨è¯¢å“¦ï½"

æ³¨æ„ï¼š
- ä¿æŒä¸“ä¸šæ€§ï¼Œé¿å…è¿‡åº¦ä½¿ç”¨è¡¨æƒ…ç¬¦å·
- ç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
- ä½¿ç”¨"\n\n"åˆ†éš”é•¿æ¶ˆæ¯

æ‹ŸäººåŒ–å›å¤ï¼š"""
    
    messages = [
        SystemMessage(content=humanize_prompt),
        HumanMessage(content="è¯·è¿›è¡Œæ‹ŸäººåŒ–å¤„ç†")
    ]
    
    response = await m.ainvoke(messages, config)
    return {"humanized_response": response.content}

async def final_response(state: CustomerServiceState, config: RunnableConfig) -> CustomerServiceState:
    """æœ€ç»ˆå›å¤ï¼šå°†æ‹ŸäººåŒ–å›å¤æ·»åŠ åˆ°æ¶ˆæ¯ä¸­"""
    humanized_response = state.get("humanized_response", "")
    if humanized_response:
        return {"messages": [AIMessage(content=humanized_response)]}
    else:
        # å¦‚æœæ²¡æœ‰æ‹ŸäººåŒ–å›å¤ï¼Œä½¿ç”¨æ¨ç†å›å¤
        reasoning_response = state.get("reasoning_response", "")
        return {"messages": [AIMessage(content=reasoning_response)]}

@tool
async def get_user_orders_info(user_token: str, status_alias: str = None) -> Dict[str, Any]:
    """Get user's order information."""
    try:
        orders = await get_user_orders(user_token, status_alias)
        return {
            "success": True,
            "orders": [order.dict() for order in orders],
            "count": len(orders)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "orders": [],
            "count": 0
        }

@tool
async def get_user_parcels_info(user_token: str) -> Dict[str, Any]:
    """Get user's parcel information."""
    try:
        parcels = await get_user_parcels(user_token)
        return {
            "success": True,
            "parcels": [parcel.dict() for parcel in parcels],
            "count": len(parcels)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "parcels": [],
            "count": 0
        }

# Define the graph
agent = StateGraph(CustomerServiceState)

# Add nodes
agent.add_node("get_user_info", get_user_information)
agent.add_node("category_analyzer", categorize_customer_message)
agent.add_node("reasoning", reasoning_response)
agent.add_node("self_check", self_check_response)
agent.add_node("humanize", humanize_response)
agent.add_node("final_response", final_response)

# å¹¶è¡Œæ‰§è¡Œï¼šç”¨æˆ·èƒŒæ™¯ä¿¡æ¯æŸ¥è¯¢å’Œé—®é¢˜åˆ†ç±»
# ä»STARTå¼€å§‹ï¼ŒåŒæ—¶æ‰§è¡Œget_user_infoå’Œcategory_analyzer
agent.add_edge(START, "get_user_info")
agent.add_edge(START, "category_analyzer")

# ä¸²è¡Œæ‰§è¡Œï¼šæ¨ç†å›ç­”ã€è‡ªæˆ‘æ£€æŸ¥ã€æ‹Ÿäººå›å¤
agent.add_edge("get_user_info", "reasoning")
agent.add_edge("category_analyzer", "reasoning")
agent.add_edge("reasoning", "self_check")

# æ¡ä»¶åˆ†æ”¯ï¼šå¦‚æœè‡ªæˆ‘æ£€æŸ¥é€šè¿‡ï¼Œç»§ç»­æ‹ŸäººåŒ–ï¼›å¦åˆ™é‡æ–°æ¨ç†
def should_continue(state: CustomerServiceState) -> str:
    """å†³å®šæ˜¯å¦ç»§ç»­åˆ°æ‹ŸäººåŒ–æ­¥éª¤"""
    if state.get("self_check_passed", False):
        return "humanize"
    else:
        return "reasoning"  # é‡æ–°æ¨ç†

agent.add_conditional_edges("self_check", should_continue)

agent.add_edge("humanize", "final_response")
agent.add_edge("final_response", END)

# Compile the agent with parallel execution
customer_service_agent = agent.compile(
    checkpointer=MemorySaver(),
)
customer_service_agent.name = "customer-service-agent"


# ä½¿ç”¨ç¤ºä¾‹
async def example_customer_service_usage():
    """å®¢æœæ™ºèƒ½ä½“ä½¿ç”¨ç¤ºä¾‹"""
    
    # æ¨¡æ‹Ÿç”¨æˆ·æ¶ˆæ¯
    user_message = "Hi, I want to check my order status"
    user_token = "example_user_token_123"
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=user_message)]
    }
    
    # é…ç½®ï¼ŒåŒ…å«user_token
    config = {
        "configurable": {
            "user_token": user_token,
            "model": settings.DEFAULT_MODEL
        }
    }
    
    try:
        # è¿è¡Œæ™ºèƒ½ä½“
        result = await customer_service_agent.ainvoke(initial_state, config)
        
        # è·å–AIå›å¤
        ai_messages = [msg for msg in result["messages"] if isinstance(msg, AIMessage)]
        
        logger.info("Customer Service Agent Response:")
        for msg in ai_messages:
            logger.info(f"AI: {msg.content}")
            
        # æ‰“å°ç”¨æˆ·ä¿¡æ¯ï¼ˆå¦‚æœè·å–æˆåŠŸï¼‰
        if result.get("user_info"):
            user_info = result["user_info"]
            logger.info(f"\nUser Info Retrieved:")
            logger.info(f"- Email: {user_info.email}")
            logger.info(f"- VIP Level: {user_info.vip_level}")
            logger.info(f"- Balance: {user_info.balance_cny} CNY")
            
        # æ‰“å°å¹¶è¡Œæ‰§è¡Œçš„ç»“æœ
        logger.info(f"\nParallel Execution Results:")
        logger.info(f"- Categories: {result.get('categories', {})}")
        logger.info(f"- Background Info: {result.get('background_info', {})}")
            
    except Exception as e:
        logger.info(f"Error running customer service agent: {e}")

# æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ
async def test_parallel_execution():
    """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œæ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    logger.info("Testing parallel execution of get_user_info and category_analyzer...")
    
    # æ¨¡æ‹Ÿç”¨æˆ·æ¶ˆæ¯
    user_message = "How much is shipping to Germany?"
    user_token = "test_user_token"
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=user_message)]
    }
    
    # é…ç½®
    config = {
        "configurable": {
            "user_token": user_token,
            "model": settings.DEFAULT_MODEL
        }
    }
    
    try:
        # è¿è¡Œæ™ºèƒ½ä½“
        result = await customer_service_agent.ainvoke(initial_state, config)
        
        logger.info("âœ… Parallel execution test completed!")
        logger.info(f"Categories: {result.get('categories', {})}")
        logger.info(f"User Info: {result.get('user_info', 'Not retrieved')}")
        logger.info(f"Background Info: {result.get('background_info', {})}")
        
        return True
        
    except Exception as e:
        logger.info(f"âŒ Parallel execution test failed: {e}")
        return False
